{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9689998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maryamsaad/Documents/Agentic_OCR/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from surya.foundation import FoundationPredictor\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a60513",
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation_predictor = FoundationPredictor(device='mps')\n",
    "recognition_predictor = RecognitionPredictor(foundation_predictor)\n",
    "detection_predictor = DetectionPredictor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210ac066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def ocr_pdf(pdf_paths, dpi=300):\n",
    "    images = []\n",
    "\n",
    "    # Case 1: single PDF file (string)\n",
    "    if isinstance(pdf_paths, str):\n",
    "        if os.path.isfile(pdf_paths):\n",
    "            return convert_from_path(pdf_paths, dpi=dpi)\n",
    "        else:\n",
    "            raise ValueError(\"Single path provided, but file does not exist.\")\n",
    "\n",
    "    # Case 2: list of PDF files\n",
    "    elif isinstance(pdf_paths, list):\n",
    "        for pdf_path in tqdm(pdf_paths, desc=\"Converting PDFs\"):\n",
    "            if os.path.isfile(pdf_path) and pdf_path.lower().endswith(\".pdf\"):\n",
    "                imgs = convert_from_path(pdf_path, dpi=dpi)\n",
    "                images.extend(imgs)\n",
    "            else:\n",
    "                print(f\"Skipping invalid PDF: {pdf_path}\")\n",
    "\n",
    "        return images\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"pdf_paths must be a string or a list of PDF paths\")\n",
    "\n",
    "pdf_list=['/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/10 - 19/12650350001 8.pdf',\n",
    "          '/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/20 - 29/12641980001 4.pdf',\n",
    "          '/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/30 - 39/12711260001 5.pdf',\n",
    "          '/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/40 - 49/12638690001 15.pdf',\n",
    "          '/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/50-60/12640070001 P4.pdf',\n",
    "          '/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/60- 69/12641550001 4.pdf',\n",
    "          '/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/70 - 79/12639710001 5.pdf',\n",
    "          '/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/80 - 90/12638700001 5.pdf',\n",
    "          '/Users/maryamsaad/Documents/layout_detection/ocr/testing_data/90 - 99/12638720001 6.pdf'\n",
    "          ]\n",
    "\n",
    "pdfs=ocr_pdf(\"/Users/maryamsaad/Documents/layout_detection/ocr/simplified.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da2bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def remove_tashkeel(text):\n",
    "    # Arabic diacritics unicode range\n",
    "    tashkeel_pattern = re.compile(r'[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]')\n",
    "    return tashkeel_pattern.sub('', text)\n",
    "def normalize_arabic(text):\n",
    "    \"\"\"\n",
    "    Normalizes Arabic characters and removes OCR artifacts.\n",
    "    \"\"\"\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"و\", text)\n",
    "    text = re.sub(\"ئ\", \"ي\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"  \", \" \", text)\n",
    "    text = re.sub(\"[ًٌٍَُِّْ]\", \"\", text)\n",
    "    text = re.sub(r\"[\\|\\)\\(\\:\\-\\;\\\\\\/]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', text)\n",
    "    text = re.sub(r'[A-Za-z0-9]+', '', text)\n",
    "    text=text.replace(\"[غير واضح]\", \"\")\n",
    "    text=text.replace(\"<>\", \"\")\n",
    "    text=text.replace(\">\", \"\")\n",
    "    text=text.replace(\">\", \"\")\n",
    "    text=text.replace(\"\\n\", \" \")\n",
    "    text=remove_tashkeel(text)\n",
    "    return text.strip()\n",
    "def html_to_text(html_str: str) -> str:    \n",
    "    \"\"\"\n",
    "    Converts HTML content to plain text.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa8ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]7s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]6it/s]\n",
      "Detecting text regions: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LayoutDetector' object has no attribute 'get_predictor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m pdf_path = \u001b[33m'\u001b[39m\u001b[33m/Users/maryamsaad/Documents/layout_detection/single_col_test.pdf\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m text=\u001b[43mocr_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mocr_pdf\u001b[39m\u001b[34m(pdf_path, dpi)\u001b[39m\n\u001b[32m     12\u001b[39m pil_textboxes = [Image.fromarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m preprocessed[page_idx]]\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# pass detection predictor if your recognizer needs it\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m det_predictor = \u001b[43mtext_detector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_predictor\u001b[49m()\n\u001b[32m     15\u001b[39m ocr_results = ocr_model.predict(pil_textboxes, det_predictor)\n\u001b[32m     16\u001b[39m all_ocr_results[page_idx] = ocr_results\n",
      "\u001b[31mAttributeError\u001b[39m: 'LayoutDetector' object has no attribute 'get_predictor'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "def OCR(img): \n",
    "    predictions = recognition_predictor([img], det_predictor=detection_predictor) \n",
    "    ocr_text = '' \n",
    "    for item in predictions: \n",
    "        text_lines = item.text_lines \n",
    "        for text_line in text_lines: \n",
    "            text = text_line.text \n",
    "            ocr_text += text + '\\n' \n",
    "    return ocr_text.strip()\n",
    "\n",
    "\n",
    "def run_pdf_ocr(pdf_path, limit=None):\n",
    "    # Load page images from PDF\n",
    "    pages = ocr_pdf(pdf_path, dpi=300)\n",
    "    results = {}\n",
    "    predictions = []\n",
    "\n",
    "    for idx, img_path in tqdm(enumerate(pages, start=1), desc=\"Running OCR\"):\n",
    "        \n",
    "        # optional: limit number of pages\n",
    "        if limit and idx > limit:\n",
    "            break\n",
    "        \n",
    "        # Load image\n",
    "        img = img_path  # already a PIL Image\n",
    "\n",
    "        # OCR prediction\n",
    "        pred_text = OCR(img)\n",
    "        pred_text = normalize_arabic(pred_text)\n",
    "        pred_text = html_to_text(pred_text)\n",
    "\n",
    "        # Save for overall metrics\n",
    "        predictions.append(pred_text)\n",
    "\n",
    "\n",
    "        results[idx] = {\n",
    "            \"image\": img_path, \n",
    "            \"pred\": pred_text\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "results=run_pdf_ocr(\"/Users/maryamsaad/Documents/layout_detection/ocr/simplified.pdf\")\n",
    "# results=run_pdf_ocr(pdf_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1255a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic_OCR (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
